{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Markov chain is a stochastic process that models a finite set of states, \n",
    "with fixed conditional probabilities of transitioning, or moving, \n",
    "from one given state to another.\n",
    "\n",
    "the model only knows the previous history and makes the predictions and \n",
    "likelihood of future states or events.\n",
    "\n",
    "Applications of Markov models in NLP.\n",
    "\n",
    "1) Text generation (we will be building this in the next part).\n",
    "2) Financial modeling and forecasting (including trading algorithms).\n",
    "3) Logistics: modeling future deliveries or trips.\n",
    "4) Search engines: PageRank can be seen as modeling a random internet surfer \n",
    "with a Markov chain.\n",
    "5) Lyrics generation\n",
    "6) Programming language code generation Also, we can understand that Markov chains \n",
    "are being used to solve probabilistic reasoning problems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building text generator using Markov Chains\n",
    "### character-based model\n",
    "\n",
    "\n",
    "1. We will save the last ‘K’ characters and the ‘K+1’ character from the training corpus \n",
    "and save them in a lookup table.\n",
    "2. We will generate all possible values of X and Y.\n",
    "3. using lookup table, we will calculate the probability values for the occurance\n",
    "of Y after X and generate our Markov Chains.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generateTable(data,k=4):\n",
    "\n",
    "    T = {}\n",
    "\n",
    "    for i in range(len(data)-k):\n",
    "        X = data[i:i+k]\n",
    "        Y = data[i+k]\n",
    "\n",
    "        if T.get(X) is None:\n",
    "            T[X] = {}\n",
    "            T[X][Y] = 1\n",
    "        else:\n",
    "            if T[X].get(Y) is None:\n",
    "                T[X][Y] = 1\n",
    "            else:\n",
    "                T[X][Y] +=1\n",
    "    \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hell': {'o': 2, 'i': 1}, 'ello': {' ': 2}, 'llo ': {'h': 2}, 'lo h': {'e': 2}, 'o he': {'l': 2}, ' hel': {'l': 2}}\n"
     ]
    }
   ],
   "source": [
    "T = generateTable(\"hello hello helli\")\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertFreqToProb(T):\n",
    "    for kx in T.keys():\n",
    "        s = float(sum(T[kx].values()))\n",
    "        for k in T[kx].keys():\n",
    "            T[kx][k] = T[kx][k]/s\n",
    "            \n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hell': {'o': 0.6666666666666666, 'i': 0.3333333333333333}, 'ello': {' ': 1.0}, 'llo ': {'h': 1.0}, 'lo h': {'e': 1.0}, 'o he': {'l': 1.0}, ' hel': {'l': 1.0}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'We summed up the frequency values for a particular key and \\nthen divided each frequency value of that key by that summed value \\nto get our probabilities.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = ConvertFreqToProb(T)\n",
    "print(T)\n",
    "\n",
    "'''We summed up the frequency values for a particular key and \n",
    "then divided each frequency value of that key by that summed value \n",
    "to get our probabilities.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's input text file and generate text from it.\n",
    "\n",
    "text_path = \"datasets/train_corpus.txt\"\n",
    "\n",
    "def load_text(filename):\n",
    "    with open(filename,encoding='utf8') as f:\n",
    "        return f.read().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "text = load_text(text_path)\n",
    "print('dataset loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MarkovChain(text,k=4):\n",
    "    T = generateTable(text,k)\n",
    "    T = ConvertFreqToProb(T)\n",
    "\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "model = MarkovChain(text)\n",
    "print('Model Created Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next(ctx,model,k):\n",
    "\n",
    "    ctx = ctx[-k:]\n",
    "    if model.get(ctx) is None:\n",
    "        return None\n",
    "    possible_Chars = list(model[ctx].keys())\n",
    "    possible_values = list(model[ctx].values())\n",
    "\n",
    "    #print(possible_Chars)\n",
    "    #print(possible_values)\n",
    "\n",
    "    return np.random.choice(possible_Chars,p=possible_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateText(starting_sent,k=4,maxLen=1000):\n",
    "\n",
    "    sentence = starting_sent\n",
    "    ctx = starting_sent[-k:]\n",
    "\n",
    "    for ix in range(maxLen):\n",
    "        next_prediction = sample_next(ctx,model,k)\n",
    "        sentence += next_prediction\n",
    "        ctx = sentence[-k:]\n",
    "    \n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear country and awareness, their misery.\n",
      "\n",
      "my dear country days, reports are celebrating this sessions of constitutional states crossed? jalianwala bagh. how order the countrymen, once and the coming the festival of our country. i heartily great service for that time, when our country, our countrymen hanged on the message of confidence to be oppressed? jalianwala bagh. how long. those whom even seas with flood wishes of the soldiers of the tricoloring to the celebrational of our nilgiris independence, who is going the tricolor flag to lives, have lost their sacrifice personnel, forceful with hard world's sixth largest the hanged ones due to social justice of the full of freedom the new consciousness, flower and in such a constitution of the seen full of the evidence. the army of the tricolor flag, in the leadership of freedom of oppression was demanding a consciousness, new excitement was entirely corners of independence from difficulties, many good reports of the common many revolution of the celebrating from to the triumphs went was entirely dear countrymen, on the seven seas and give fight new excitement made soldiers uttarakhand, himachal, many-many corners of the message of nilkurinya grow in their help with hard world's sunrise heroes of the tricolor, in our parliament, among with a consciousness to the celebrating the world, today, i will remember the country. the are coming their sacrifice today andhra pradesh - our loved ones due to protect that corner of their lives, have fights by plowing the countrymen hanged on the lok sabha has broughters of independence.\n",
      "\n",
      "today, i bow my heart to the tried the tricolor of independence, for the countrymen,\n",
      "\n",
      "many, many good rajya bapu. many good reports are celebrating in a sensitivity and sacrifice more forceful with hard world's sixth largest the tricolor flag on the country. those families of freedom, i will remember the country, with flower lives india has registered force, when our daught new heights.\n",
      "\n",
      "today and die, t\n"
     ]
    }
   ],
   "source": [
    "text = generateText(\"dear\",k=4,maxLen=2000)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text generated does not have a good context and sometimes the words can even have no relationship between them. This happens because we are only storing the syntactic information and building a model on top of that. For generating more understandable text, you can use a LSTM (Long Short-Term Memory) based model, GRU, transformer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
