{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5355f9c8",
   "metadata": {},
   "source": [
    "### Recurrent Neural Network\n",
    "\n",
    "\n",
    "ANN and CNN fails because they are stateless. They can't remember past information.\n",
    "Ex: \"This is good movie\" and \"This is not good movie\" will produce same output because of statelessness. \n",
    "\n",
    "RNN is sequential model. It take one or more input vectors and generate one or more outputs vectors, and the outputs determined not only by weights applied to inputs like NN but also by \"hidden\" state vector, representing meaning based on inputs/outputs beforehand. Therefore, the same input may generate a different output depending on series' previous inputs.\n",
    "\n",
    "This looping back to better understanf the sentence is called \"feedback loop\" or \"temporal loop\". Compared to NN, RNN uses feedback loops, such as Backpropogation Through Time (BPTT), to loop information back into the netowrk during computational cycle. This is what links inputs together and is also what enables sequential and temporal data processing by RNNs.\n",
    "\n",
    "Applications: sentiment analysis, text summarization, machine translation, image captioning\n",
    "\n",
    "The \"Vanishing gradient\" problem:\n",
    "In NN information passes through the input layer to output layer, and the error is back-propagated to update weights. In RNN, similar thing happens, but information travels through time, and we calculate error at each time point. To minimize the error, every single neuron that participates in calculating the output should have its weight updated. Hence, many neurons' weights need to be updated.\n",
    "\n",
    "We start by randomizing the weights, which are close to zero. The weights used to connect the hidden layers to themselves in the unrolled temporal loop, but when we start with very small values, gradient becomes very small and it makes harder for the network to update the weights. Thus, longer to get to the final result.\n",
    "\n",
    "The training for the time point, t, is happening based on the inputs coming from untrained layers. So, because of the vanishing gradient, the whole network is not being trained properly. For the vanishing gradient problem, the further you go through the network, the lower your gradient is, and the harder it is to train the weights, which has a domino effect on all of the further weights throughout the network.\n",
    "\n",
    "Solution:\n",
    "Initialize weights properly.\n",
    "Have echi state network.\n",
    "LSTM\n",
    "\n",
    "Exploding gradient solution:\n",
    "stop back-propagation early, leades to less optimal result.\n",
    "Penalize or artificially reduce the gradient.\n",
    "Put a maximum limit on gradient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a999efd",
   "metadata": {},
   "source": [
    "### Types of RNN architectures\n",
    "\n",
    "1. One to One (non-sequential): basically represents multi-layer perceptron because it takes single input and generates single output.\n",
    "\n",
    "2. One to Many: Accepts single input and generates multiple outputs at each time step. Usecase: Image captioning: model take image as input and generate output at each time step defining that image.\n",
    "\n",
    "3. Many to One: Many inputs to generate one output. Usecase: Sentiment analysis - we provide sequence of text (different inputs at each time step), and the model then generate a single output(review rating)\n",
    "\n",
    "4. Many to Many: Accepts many inputs and generate multiple outputs. Output of t-1 is necessary to generate output at time t. Usecase: POS tagging (part of speech) - we give model input sequence of text (multiple inputs) and the model then predicts the POS tags for each word. Sppech recognition.\n",
    "\n",
    "5. Encoder - Decoder: Special type of many to many RNN. In this RNN is seperated into two parts: encoder, decoder. Encoder -> contect vector -> decoder -> output. Usecase: machine translation, where we feed text in one language to the model, and the model encodes and decodes it to generate text in another language. We seperate encoder from decoder because it is not necessary that we have corresponding word in the target language for each word in the source language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9346b",
   "metadata": {},
   "source": [
    "### Long Short Team Memory Networks (LSTM)\n",
    "\n",
    "Recurring weight (W_rec) <1 then we have vanishing gradient and if W_rec >1 then we have exploding gradient problem. LSTM made W_rec=1 to solve the problem. \n",
    "\n",
    "Instead of having single NN in cell, LSTM cell has 4 layers interacting in special way.\n",
    "\n",
    "1. Sigmoid layer: LSTM decide what information to throw away from cell state. \"forget gate layer\". It looks at H_t-1(previous cell output) and X_t(current input) and outputs a number between 0 and 1 for each number in the cell state C_t-1. 1 represents completely keep and 0 represents completely delete.\n",
    "\n",
    "2. Sigmoid and Tanh layer (second and third layer): decides what new information to store in cell state. First sigmoid layer \"input gate layer\" decides which values to update. Next tanh layer creates vector of new candidate values that could be added to the state. In the next step, we combined these two to create an update to the state. This create output from the current cell to be fed as input to next cell.\n",
    "\n",
    "3. sigmoid layer (forth layer): decides what to output for current layer H_t. first sigmoid will run to decide what to output and then we put the cell state through tanh(push values between -1 and 1) and multiply it by the output of the sigmoid gate, so we only output the parts that we decided on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b1e0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "#load the dataset\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "\n",
    "#train_data and test_data are sequences of integers (word indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "639ce7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a10b6332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 5760, 394, 354, 4, 123, 9, 1035, 1035, 1035, 10, 10, 13, 92, 124, 89, 488, 7944, 100, 28, 1668, 14, 31, 23, 27, 7479, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 7944, 451, 202, 14, 6, 717]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee818c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#decode one of the reviews back to english words\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in train_data[0]])\n",
    "print(decoded_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dddda548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform padding to make input length same for all sentences vector.\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "X_train = sequence.pad_sequences(train_data,maxlen=500)\n",
    "X_test = sequence.pad_sequences(test_data,maxlen=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cacacd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 500)\n",
      "(25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd1e7001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#Create model architecture\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "#vocabulary, vector size of embedding matrix\n",
    "model.add(Embedding(10000,64)) #output size = (batch_szie,maxlen=500,k=64)\n",
    "\n",
    "#maxlen times(500) unrolling of RNN cell ine step at a time. RNN produce vector of length 32 vector\n",
    "model.add(SimpleRNN(32)) \n",
    "#fully connected layer\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "print(model.summary())\n",
    "\n",
    "#Here, we have single mebedding matrix which will get trained and pass output to RNN cells.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dedf48fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0bd6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks: ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\",monitor = \"val_loss\",verbose=0,\n",
    "                                save_best_only=True,save_weights_only=False)\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_acc',patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4be106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-31 13:08:31.152806: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117s/step - acc: 0.5394 - loss: 0.6835  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18742s\u001b[0m 119s/step - acc: 0.5823 - loss: 0.6615 - val_acc: 0.6078 - val_loss: 0.6506\n",
      "Epoch 2/10\n",
      "\u001b[1m 77/157\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24:13:57\u001b[0m 1090s/step - acc: 0.7436 - loss: 0.5157"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "\n",
    "hist = model.fit(X_train,train_labels,validation_split=0.2,epochs=10,\n",
    "                    batch_size=128,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f1d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = hist.history['acc']\n",
    "val_acc = hist.history['val_acc']\n",
    "epochs = range(1,len(loss)+1)#########\n",
    "\n",
    "plt.title(\"Accuracy vs Epochs\")\n",
    "plt.plot(epochs,acc,label=\"Training Acc\")\n",
    "plt.plot(epochs,val_acc,label=\"Val Acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884cb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the loss\n",
    "\n",
    "loss = his.history['loss']\n",
    "val_loss = hist.history['val_loss']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "plt.title(\"Loss vs Epochs\")\n",
    "plt.plot(epochs,loss,label=\"Training Loss\")\n",
    "plt.plot(epochs,val_loss,label=\"Val Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict sentiment of new sentence\n",
    "\n",
    "sent = \"This movie is really bad . I do not like this movie because the direction was horrible .\"\n",
    "inp = []\n",
    "\n",
    "\n",
    "# Convert each word to integer\n",
    "for word in sent.split():\n",
    "  if word in word_index.keys():\n",
    "    inp.append(word_index[word])\n",
    "  else:\n",
    "    inp.append(1)\n",
    "\n",
    "print(inp) \n",
    "\n",
    "# Perform the padding\n",
    "final_input = sequence.pad_sequences([inp],maxlen=500)\n",
    "\n",
    "# Finally predict the sentiment\n",
    "model.predict(final_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
